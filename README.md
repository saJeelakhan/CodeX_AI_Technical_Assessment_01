# CodeX AI Technical Assessment

This project classifies sentences as **Greeklish** (Greek written in Latin characters) or **English** using real-world scraped data and a Logistic Regression model.

---

## ğŸ“ Files Overview

- `main.ipynb` â€“ Complete pipeline: scraping, preprocessing, training, evaluation  
- `model/` â€“ Trained model and TF-IDF vectorizer  
- `initial_dataset.csv` â€“ Raw data  
- `preprocessed_sentences.csv` â€“ Cleaned data  
- `requirements.txt` â€“ Dependencies  
- `Documentation.pdf` â€“ Full project explanation  

---

## ğŸ“Š Data Sources

**Greeklish**  
- Reddit (`r/greece`)  
- Insomnia.gr Forum  
- YouTube Comments (`_akH1Bns2B8`)  

**English**  
- Reddit (`r/AskReddit`)  
- Wikipedia (AI article)  

---

## ğŸ§¹ Preprocessing Steps

- Lowercasing  
- Sentence splitting (., !, ?)  
- Special character and digit removal (regex)  
- Tokenization using NLTK  
- Stopword removal  
- Rebuilding cleaned sentences  

---

## ğŸ¤– Model Details

- **Classifier:** Logistic Regression  
- **Vectorizer:** TF-IDF (max 5000 features)  
- **Train/Test Split:** 80/20 (stratified)  

### ğŸ“ˆ Evaluation Results

- **Accuracy:** 93.22%  
- **Precision:** 94.18%  
- **Recall:** 93.22%  
- **F1-Score:** 93.27%  

---

## ğŸ§ª Prediction Example

```python
predict_text("ti kaneis")  # â†’ "Greeklish"
predict_text("Hello, how are you?")  # â†’ "English"
